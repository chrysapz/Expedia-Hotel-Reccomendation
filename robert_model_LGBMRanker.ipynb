{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:19:51.698051983Z",
     "start_time": "2023-05-24T15:19:51.653999811Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:19:51.702247036Z",
     "start_time": "2023-05-24T15:19:51.698217227Z"
    }
   },
   "outputs": [],
   "source": [
    "def _dsg_numerator(rel, use_2pow):\n",
    "    if use_2pow:\n",
    "        return 2**rel-1\n",
    "    else:\n",
    "        return rel\n",
    "\n",
    "\n",
    "def calc_ndcg(rel_true, rel_est, n=5, use_2pow=True):\n",
    "    assert len(rel_est) == len(rel_true)\n",
    "    rel_true = np.asarray(rel_true)\n",
    "    rel_est = np.asarray(rel_est)\n",
    "\n",
    "    discount = 1 / np.log(np.arange(2, len(rel_true) + 2))\n",
    "    discount[n:] = 0\n",
    "\n",
    "    dsg_N = discount.dot(_dsg_numerator(rel_est, use_2pow))\n",
    "    idsg_N = discount.dot(_dsg_numerator(rel_true, use_2pow))\n",
    "    EPS = 1e-6\n",
    "\n",
    "    return dsg_N/(idsg_N+EPS)\n",
    "\n",
    "\n",
    "def ndcg_dmt(predicted_scores, n=5, use_2pow=True):\n",
    "    ranked_scores = np.sort(predicted_scores)[::-1] # sorted descending, highest score first\n",
    "    return calc_ndcg(ranked_scores, predicted_scores, n=n, use_2pow=use_2pow)\n",
    "\n",
    "\n",
    "def ndcg_sklearn(predicted_scores, n=5):\n",
    "    ranked_scores = np.sort(predicted_scores)[::-1] # sorted descending, highest score first\n",
    "    return ndcg_score(np.asarray([ranked_scores]), np.asarray([predicted_scores]), k=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:19:51.705546292Z",
     "start_time": "2023-05-24T15:19:51.698339353Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_missing(df, col):\n",
    "    miss_cnt = df[col].isna().sum()\n",
    "    if miss_cnt == 0:\n",
    "        return\n",
    "    total_cnt = len(df[col])\n",
    "    perc_miss = 100 * miss_cnt / total_cnt\n",
    "    print(f'{col} missing count {miss_cnt} out of {total_cnt} => {round(perc_miss)}% missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:27.190464059Z",
     "start_time": "2023-05-24T15:19:51.704168314Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"data/joined_all_features.csv.zip\", index_col=0)\n",
    "#df = pd.read_csv(\"data/joined_all_features_revealed.csv.zip\", index_col=0)\n",
    "#df.drop(columns=['srch_id_match'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>prop_location_score2_d_srch_id</th>\n",
       "      <th>price_usd_ld_srch_id__prop_starrating</th>\n",
       "      <th>booking_prob_per_prop_id_d_srch_id</th>\n",
       "      <th>click_prob_per_prop_id_d_srch_id</th>\n",
       "      <th>price_hist_logdiff_d_srch_id</th>\n",
       "      <th>visitor_hist_adr_usd_logdiff_d_srch_id</th>\n",
       "      <th>srch_query_affinity_score_d_srch_id</th>\n",
       "      <th>target_cls</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>prop_srch_dest_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>427</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125626</td>\n",
       "      <td>-0.015505</td>\n",
       "      <td>-0.011613</td>\n",
       "      <td>0.218860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5762</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>3.5</td>\n",
       "      <td>147.02</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129212</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>-0.014857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.11441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8178</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198177</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>-0.010634</td>\n",
       "      <td>0.283944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8465</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044171</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>-0.010634</td>\n",
       "      <td>0.269329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10771</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450021</td>\n",
       "      <td>-0.016393</td>\n",
       "      <td>-0.014857</td>\n",
       "      <td>0.247003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  prop_id  site_id  visitor_location_country_id   \n",
       "0      427        1        5                          219  \\\n",
       "1     5762        1        5                          219   \n",
       "2     8178        1        5                          219   \n",
       "3     8465        1        5                          219   \n",
       "4    10771        1        5                          219   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id   \n",
       "0                      NaN                   NaN              219  \\\n",
       "1                      3.5                147.02              219   \n",
       "2                      NaN                   NaN              219   \n",
       "3                      NaN                   NaN              219   \n",
       "4                      NaN                   NaN              219   \n",
       "\n",
       "   prop_starrating  prop_review_score  prop_brand_bool  ...   \n",
       "0                2                NaN                1  ...  \\\n",
       "1                2                NaN                1  ...   \n",
       "2                2                NaN                1  ...   \n",
       "3                2                NaN                1  ...   \n",
       "4                2                NaN                1  ...   \n",
       "\n",
       "   prop_location_score2_d_srch_id  price_usd_ld_srch_id__prop_starrating   \n",
       "0                             NaN                               0.125626  \\\n",
       "1                             NaN                               0.129212   \n",
       "2                             NaN                               0.198177   \n",
       "3                             NaN                               0.044171   \n",
       "4                             NaN                               0.450021   \n",
       "\n",
       "   booking_prob_per_prop_id_d_srch_id  click_prob_per_prop_id_d_srch_id   \n",
       "0                           -0.015505                         -0.011613  \\\n",
       "1                           -0.017857                         -0.014857   \n",
       "2                           -0.015625                         -0.010634   \n",
       "3                           -0.015625                         -0.010634   \n",
       "4                           -0.016393                         -0.014857   \n",
       "\n",
       "   price_hist_logdiff_d_srch_id  visitor_hist_adr_usd_logdiff_d_srch_id   \n",
       "0                      0.218860                                     NaN  \\\n",
       "1                           NaN                                -0.11441   \n",
       "2                      0.283944                                     NaN   \n",
       "3                      0.269329                                     NaN   \n",
       "4                      0.247003                                     NaN   \n",
       "\n",
       "   srch_query_affinity_score_d_srch_id  target_cls  relevance_score   \n",
       "0                                  NaN         0.0              0.0  \\\n",
       "1                                  NaN         0.0              0.0   \n",
       "2                                  NaN         0.0              0.0   \n",
       "3                                  NaN         0.0              0.0   \n",
       "4                                  NaN         0.0              0.0   \n",
       "\n",
       "   prop_srch_dest_id  \n",
       "0             106475  \n",
       "1             106475  \n",
       "2             106475  \n",
       "3             106475  \n",
       "4             106475  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['target_cls'] = df_raw.booking_bool + df_raw.click_bool\n",
    "df_raw['relevance_score'] = df_raw.booking_bool * 4 + df_raw.click_bool\n",
    "# a property id can appear in multiple srch_destination_id, to make the combination unique we need a new combined id\n",
    "df_raw['prop_srch_dest_id']  = df_raw.prop_id * 100000 + df_raw.srch_destination_id\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:27.190679121Z",
     "start_time": "2023-05-24T15:20:27.154796490Z"
    }
   },
   "outputs": [],
   "source": [
    "TOP_NUM=5\n",
    "# is the position in top\n",
    "#df['top_bool'] = df['position']<=TOP_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:31.920463930Z",
     "start_time": "2023-05-24T15:20:27.154843088Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of search results - per search id\n",
    "df_raw = df_raw.merge(df_raw.groupby('srch_id').agg(prop_count = ('srch_id', 'count')), on='srch_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:35.652023838Z",
     "start_time": "2023-05-24T15:20:31.921177683Z"
    }
   },
   "outputs": [],
   "source": [
    "# top percentage: out of all the times the property appeared, how many times was it in top\n",
    "df = df_raw.merge(\n",
    "    df.query(\"is_test==0\").groupby('prop_srch_dest_id').agg(\n",
    "        top_prob_srch_prop_id = ('position', lambda x: (x <= TOP_NUM).mean()),\n",
    "        avg_position_srch_prop_id = ('position', 'mean'),\n",
    "    ), on='prop_srch_dest_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:38.476436224Z",
     "start_time": "2023-05-24T15:20:35.652717782Z"
    }
   },
   "outputs": [],
   "source": [
    "# also add average position per property id\n",
    "df = df.merge(\n",
    "    df.query(\"is_test==0\").groupby('prop_id').agg(\n",
    "        top_prob_prop_id = ('position', lambda x: (x <= TOP_NUM).mean()),\n",
    "        avg_position_prop_id = ('position', 'mean')\n",
    "    ), on='prop_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:44.209448573Z",
     "start_time": "2023-05-24T15:20:38.478561314Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.merge(\n",
    "    df.groupby('prop_srch_dest_id').agg(\n",
    "        log_appearance_count_srch_prop_id=('prop_id', lambda x: np.log(len(x))),\n",
    "        avg_res_len_srch_prop_id=('prop_count', 'mean'),\n",
    "    ),\n",
    "    on='prop_srch_dest_id')\n",
    "\n",
    "df = df.merge(\n",
    "    df.groupby('prop_id').agg(\n",
    "        log_appearance_count_prop_id=('prop_id', lambda x: np.log(len(x))),\n",
    "        avg_res_len_prop_id=('prop_count', 'mean'),\n",
    "    ),\n",
    "    on='prop_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:46.098247629Z",
     "start_time": "2023-05-24T15:20:44.211414529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate competitor information - perhaps not\n",
    "\n",
    "# add flag to indicate if any competitor has availability at a better rate\n",
    "for i in range(1, 9):\n",
    "    df[f'comp{i}_known'] = ~(df[f'comp{i}_rate'].isna() | df[f'comp{i}_inv'].isna())\n",
    "    df[f'comp{i}_better'] = df[f'comp{i}_known'] & (df[f'comp{i}_rate']==-1) & (df[f'comp{i}_inv']<=0)\n",
    "    df[f'comp{i}_worse'] = df[f'comp{i}_known'] & (df[f'comp{i}_rate']==1) & (df[f'comp{i}_inv']>=0)\n",
    "\n",
    "df['comp_known_cnt'] = sum([df[f'comp{i}_known'].astype(int) for i in range(1, 9)])\n",
    "df['comp_better_worse'] = \\\n",
    "    (sum([df[f'comp{i}_better'].astype(int) for i in range(1, 9)])\n",
    "     -sum([df[f'comp{i}_worse'].astype(int) for i in range(1, 9)]))\n",
    "\n",
    "comp_rate_cols = [f'comp{i}_rate' for i in range(1, 9)]\n",
    "df['comp_rate_sum'] = df[comp_rate_cols].fillna(0).sum(axis=1)\n",
    "\n",
    "comps = [f'comp{i}_' for i in range(1, 9)]\n",
    "#df.drop(columns=[c for c in df.columns if c[:6] in comps and c not in ('comp2_rate_percent_diff', 'comp5_rate_percent_diff', 'comp8_rate_percent_diff')], inplace=True)\n",
    "df.drop(columns=[c for c in df.columns if c[:6] in comps], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:46.707604106Z",
     "start_time": "2023-05-24T15:20:46.176800518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_position_srch_prop_id</th>\n",
       "      <th>top_prob_prop_id</th>\n",
       "      <th>avg_position_prop_id</th>\n",
       "      <th>log_appearance_count_srch_prop_id</th>\n",
       "      <th>avg_res_len_srch_prop_id</th>\n",
       "      <th>log_appearance_count_prop_id</th>\n",
       "      <th>avg_res_len_prop_id</th>\n",
       "      <th>comp_known_cnt</th>\n",
       "      <th>comp_better_worse</th>\n",
       "      <th>comp_rate_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>427</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.365385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.672131</td>\n",
       "      <td>4.60517</td>\n",
       "      <td>32.16</td>\n",
       "      <td>4.795791</td>\n",
       "      <td>31.735537</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5762</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>3.50</td>\n",
       "      <td>147.02</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.365385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.672131</td>\n",
       "      <td>4.60517</td>\n",
       "      <td>32.16</td>\n",
       "      <td>4.795791</td>\n",
       "      <td>31.735537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8178</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.365385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.672131</td>\n",
       "      <td>4.60517</td>\n",
       "      <td>32.16</td>\n",
       "      <td>4.795791</td>\n",
       "      <td>31.735537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8465</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.365385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.672131</td>\n",
       "      <td>4.60517</td>\n",
       "      <td>32.16</td>\n",
       "      <td>4.795791</td>\n",
       "      <td>31.735537</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10771</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29.365385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.672131</td>\n",
       "      <td>4.60517</td>\n",
       "      <td>32.16</td>\n",
       "      <td>4.795791</td>\n",
       "      <td>31.735537</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651972</th>\n",
       "      <td>110771</td>\n",
       "      <td>104543</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>3.85</td>\n",
       "      <td>138.19</td>\n",
       "      <td>220</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651973</th>\n",
       "      <td>110771</td>\n",
       "      <td>106966</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>3.85</td>\n",
       "      <td>138.19</td>\n",
       "      <td>220</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651974</th>\n",
       "      <td>110771</td>\n",
       "      <td>115296</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>3.85</td>\n",
       "      <td>138.19</td>\n",
       "      <td>220</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651975</th>\n",
       "      <td>110771</td>\n",
       "      <td>131902</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>3.85</td>\n",
       "      <td>138.19</td>\n",
       "      <td>220</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9651976</th>\n",
       "      <td>110771</td>\n",
       "      <td>138236</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>3.85</td>\n",
       "      <td>138.19</td>\n",
       "      <td>220</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9651977 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         srch_id  prop_id  site_id  visitor_location_country_id   \n",
       "0            427        1        5                          219  \\\n",
       "1           5762        1        5                          219   \n",
       "2           8178        1        5                          219   \n",
       "3           8465        1        5                          219   \n",
       "4          10771        1        5                          219   \n",
       "...          ...      ...      ...                          ...   \n",
       "9651972   110771   104543       32                          220   \n",
       "9651973   110771   106966       32                          220   \n",
       "9651974   110771   115296       32                          220   \n",
       "9651975   110771   131902       32                          220   \n",
       "9651976   110771   138236       32                          220   \n",
       "\n",
       "         visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id   \n",
       "0                            NaN                   NaN              219  \\\n",
       "1                           3.50                147.02              219   \n",
       "2                            NaN                   NaN              219   \n",
       "3                            NaN                   NaN              219   \n",
       "4                            NaN                   NaN              219   \n",
       "...                          ...                   ...              ...   \n",
       "9651972                     3.85                138.19              220   \n",
       "9651973                     3.85                138.19              220   \n",
       "9651974                     3.85                138.19              220   \n",
       "9651975                     3.85                138.19              220   \n",
       "9651976                     3.85                138.19              220   \n",
       "\n",
       "         prop_starrating  prop_review_score  prop_brand_bool  ...   \n",
       "0                      2                NaN                1  ...  \\\n",
       "1                      2                NaN                1  ...   \n",
       "2                      2                NaN                1  ...   \n",
       "3                      2                NaN                1  ...   \n",
       "4                      2                NaN                1  ...   \n",
       "...                  ...                ...              ...  ...   \n",
       "9651972                4                NaN                0  ...   \n",
       "9651973                4                2.5                0  ...   \n",
       "9651974                4                3.5                1  ...   \n",
       "9651975                4                4.5                0  ...   \n",
       "9651976                4                3.0                0  ...   \n",
       "\n",
       "         avg_position_srch_prop_id  top_prob_prop_id  avg_position_prop_id   \n",
       "0                        29.365385               0.0             28.672131  \\\n",
       "1                        29.365385               0.0             28.672131   \n",
       "2                        29.365385               0.0             28.672131   \n",
       "3                        29.365385               0.0             28.672131   \n",
       "4                        29.365385               0.0             28.672131   \n",
       "...                            ...               ...                   ...   \n",
       "9651972                   6.000000               0.0              6.000000   \n",
       "9651973                   3.000000               1.0              3.000000   \n",
       "9651974                   2.000000               1.0              2.000000   \n",
       "9651975                   1.000000               1.0              1.000000   \n",
       "9651976                   4.000000               1.0              4.000000   \n",
       "\n",
       "         log_appearance_count_srch_prop_id  avg_res_len_srch_prop_id   \n",
       "0                                  4.60517                     32.16  \\\n",
       "1                                  4.60517                     32.16   \n",
       "2                                  4.60517                     32.16   \n",
       "3                                  4.60517                     32.16   \n",
       "4                                  4.60517                     32.16   \n",
       "...                                    ...                       ...   \n",
       "9651972                            0.00000                      5.00   \n",
       "9651973                            0.00000                      5.00   \n",
       "9651974                            0.00000                      5.00   \n",
       "9651975                            0.00000                      5.00   \n",
       "9651976                            0.00000                      5.00   \n",
       "\n",
       "         log_appearance_count_prop_id  avg_res_len_prop_id  comp_known_cnt   \n",
       "0                            4.795791            31.735537               3  \\\n",
       "1                            4.795791            31.735537               0   \n",
       "2                            4.795791            31.735537               0   \n",
       "3                            4.795791            31.735537               3   \n",
       "4                            4.795791            31.735537               4   \n",
       "...                               ...                  ...             ...   \n",
       "9651972                      0.000000             5.000000               0   \n",
       "9651973                      0.000000             5.000000               0   \n",
       "9651974                      0.000000             5.000000               0   \n",
       "9651975                      0.000000             5.000000               0   \n",
       "9651976                      0.000000             5.000000               0   \n",
       "\n",
       "         comp_better_worse  comp_rate_sum  \n",
       "0                        0            0.0  \n",
       "1                        0            0.0  \n",
       "2                        0            0.0  \n",
       "3                        0            0.0  \n",
       "4                        0            0.0  \n",
       "...                    ...            ...  \n",
       "9651972                  0            0.0  \n",
       "9651973                  0            0.0  \n",
       "9651974                  0            0.0  \n",
       "9651975                  0            0.0  \n",
       "9651976                  0            0.0  \n",
       "\n",
       "[9651977 rows x 76 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:48.215784305Z",
     "start_time": "2023-05-24T15:20:46.707390394Z"
    }
   },
   "outputs": [],
   "source": [
    "df_devel = df.loc[df.is_test==False, [c for c in df.columns if c != 'is_test']]\n",
    "df_test = df.loc[df.is_test==True, [c for c in df.columns if c != 'is_test']]\n",
    "df_test.srch_id -= df_devel.srch_id.max()\n",
    "# del df\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:48.343394031Z",
     "start_time": "2023-05-24T15:20:48.218545591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visitor_hist_starrating missing count 4706481 out of 4958347 => 95% missing\n",
      "visitor_hist_adr_usd missing count 4705398 out of 4958347 => 95% missing\n",
      "prop_review_score missing count 240658 out of 4958347 => 5% missing\n",
      "prop_location_score2 missing count 1090348 out of 4958347 => 22% missing\n",
      "prop_log_historical_price missing count 713899 out of 4958347 => 14% missing\n",
      "price_usd missing count 31 out of 4958347 => 0% missing\n",
      "srch_query_affinity_score missing count 4640941 out of 4958347 => 94% missing\n",
      "prop_starrating_w0 missing count 169572 out of 4958347 => 3% missing\n",
      "hist_starrating_diff missing count 4706481 out of 4958347 => 95% missing\n",
      "price_hist_logdiff missing count 713927 out of 4958347 => 14% missing\n",
      "visitor_hist_adr_usd_logdiff missing count 4705398 out of 4958347 => 95% missing\n",
      "price_usd_ld_srch_id missing count 31 out of 4958347 => 0% missing\n",
      "prop_starrating_w0_d_srch_destination_id missing count 169572 out of 4958347 => 3% missing\n",
      "prop_starrating_w0_d_srch_id missing count 169572 out of 4958347 => 3% missing\n",
      "prop_review_score_d_srch_destination_id missing count 240658 out of 4958347 => 5% missing\n",
      "prop_review_score_d_srch_destination_id__prop_starrating missing count 240658 out of 4958347 => 5% missing\n",
      "prop_review_score_d_srch_id missing count 240658 out of 4958347 => 5% missing\n",
      "prop_location_score2_d_srch_destination_id missing count 1090348 out of 4958347 => 22% missing\n",
      "prop_location_score2_d_srch_destination_id__prop_starrating missing count 1090348 out of 4958347 => 22% missing\n",
      "prop_location_score2_d_srch_id missing count 1090348 out of 4958347 => 22% missing\n",
      "price_usd_ld_srch_id__prop_starrating missing count 31 out of 4958347 => 0% missing\n",
      "price_hist_logdiff_d_srch_id missing count 713927 out of 4958347 => 14% missing\n",
      "visitor_hist_adr_usd_logdiff_d_srch_id missing count 4705398 out of 4958347 => 95% missing\n",
      "srch_query_affinity_score_d_srch_id missing count 4640941 out of 4958347 => 94% missing\n"
     ]
    }
   ],
   "source": [
    "for col in df_devel.columns:\n",
    "    print_missing(df_devel, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:20:48.385263988Z",
     "start_time": "2023-05-24T15:20:48.343490498Z"
    }
   },
   "outputs": [],
   "source": [
    "# split srch_id into train and val\n",
    "all_srch_ids = df_devel.srch_id.unique()\n",
    "\n",
    "# randomly shuffle all_srch_ids using random seed 42\n",
    "RANDOM_SEED = 124\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "all_srch_ids.sort()\n",
    "rng.shuffle(all_srch_ids)\n",
    "\n",
    "VALIDATION_PROP = 0.1\n",
    "val_start_idx = int(len(all_srch_ids)*(1-VALIDATION_PROP))\n",
    "train_ids = all_srch_ids[:val_start_idx]\n",
    "val_ids = all_srch_ids[val_start_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_772347/4095871100.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data_test.drop(columns=['srch_id'], inplace=True)\n",
      "/tmp/ipykernel_772347/4095871100.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data_devel.drop(columns=['srch_id'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "columns_to_remove = [\n",
    "    #'prop_id',\n",
    "    #'srch_destination_id',\n",
    "    #'prop_srch_dest_id',\n",
    "\n",
    "    'visitor_location_country_id', # todo: visitor_location_country_id: combine with prop_country_id and keep the N most clicked/booked combinations,\n",
    "    'visitor_hist_starrating', # normalized\n",
    "    'visitor_hist_adr_usd', # normalized\n",
    "    'prop_country_id', # todo:\n",
    "    #'prop_starrating', # normalized\n",
    "    #'prop_review_score', # normalized\n",
    "    #'prop_location_score1', # normalized\n",
    "    #'prop_location_score2', # normalized\n",
    "    'prop_log_historical_price', # normalized\n",
    "    'position', # todo: maybe mean/stdev_position_per_prop\n",
    "    'price_usd', # normalized\n",
    "    #'srch_query_affinity_score', # normalized\n",
    "    'prop_starrating_w0', # normalized\n",
    "\n",
    "    'prop_location_score1_d_srch_id',\n",
    "    'prop_location_score1_d_srch_destination_id__prop_starrating',\n",
    "    'prop_location_score2_d_srch_id',\n",
    "    'prop_location_score2_d_srch_destination_id__prop_starrating',\n",
    "\n",
    "    'booking_prob_per_prop_id_d_srch_id',\n",
    "    'click_prob_per_prop_id_d_srch_id',\n",
    "    'booking_prob_per_prop_id',\n",
    "    'click_prob_per_prop_id',\n",
    "\n",
    "    # 'site_id',\n",
    "    # 'prop_starrating',\n",
    "    # 'prop_review_score',\n",
    "    # 'prop_brand_bool',\n",
    "    # 'prop_location_score2',\n",
    "    # 'promotion_flag',\n",
    "    # 'srch_length_of_stay',\n",
    "    # 'srch_booking_window',\n",
    "    # 'srch_adults_count',\n",
    "    # 'srch_children_count',\n",
    "    #'srch_room_count',\n",
    "    'srch_saturday_night_bool',\n",
    "    # 'srch_query_affinity_score',\n",
    "    # 'random_bool',\n",
    "    # 'comp_known_cnt',\n",
    "    # 'comp_better_worse',\n",
    "    'comp_rate_sum',\n",
    "    # 'hist_starrating_diff',\n",
    "    # 'price_hist_logdiff',\n",
    "    # 'visitor_hist_adr_usd_logdiff',\n",
    "    # 'same_country',\n",
    "    # 'booking_prob_per_prop_id',\n",
    "    # 'click_prob_per_prop_id',\n",
    "    # 'price_usd_ld_srch_id',\n",
    "    #'prop_starrating_w0_d_srch_destination_id',\n",
    "    # 'prop_starrating_w0_d_srch_id',\n",
    "    #'prop_review_score_d_srch_destination_id',\n",
    "    #'prop_review_score_d_srch_destination_id__prop_starrating',\n",
    "    # 'prop_review_score_d_srch_id',\n",
    "    #'prop_location_score1_d_srch_destination_id',\n",
    "    #'prop_location_score2_d_srch_destination_id',\n",
    "    # 'price_usd_ld_srch_id__prop_starrating',\n",
    "    # 'booking_prob_per_prop_id_d_srch_id',\n",
    "    # 'click_prob_per_prop_id_d_srch_id',\n",
    "    # 'price_hist_logdiff_d_srch_id',\n",
    "    # 'visitor_hist_adr_usd_logdiff_d_srch_id',\n",
    "\n",
    "    #'midstay_week',\n",
    "    'midstay_month',\n",
    "    'midstay_dayofyear',\n",
    "    #'midstay_dayofweek',\n",
    "    'booking_week',\n",
    "    'booking_month',\n",
    "    'booking_dayofyear',\n",
    "    #'booking_dayofweek' ,\n",
    "    \n",
    "    'prop_count',\n",
    "    'top_prob_srch_prop_id',\n",
    "    'avg_res_len_srch_prop_id',\n",
    "    'avg_position_srch_prop_id',\n",
    "    'log_appearance_count_srch_prop_id',\n",
    "    #'top_prob_prop_id',\n",
    "    #'avg_res_len_prop_id'\n",
    "    #'avg_position_prop_id',\n",
    "    #'log_appearance_count_prop_id',\n",
    "]\n",
    "predictor_cols = [c for c in df_devel.columns if ((c not in ('position', 'booking_bool', 'click_bool', 'target_cls', 'relevance_score', 'is_test')) and (c not in columns_to_remove))]\n",
    "\n",
    "def get_groups(df):\n",
    "    grp = df.groupby('srch_id').srch_id.count()\n",
    "    return grp.values\n",
    "\n",
    "df_devel = df_devel.set_index('srch_id').sort_index().reset_index()\n",
    "\n",
    "df_data_train = df_devel.loc[df_devel.srch_id.isin(train_ids), predictor_cols]\n",
    "groups_train = get_groups(df_data_train)\n",
    "# #df_data_train = df_data_train.dropna() # let's see what happens if we drop all NAs\n",
    "df_train = df_devel.loc[df_data_train.index]\n",
    "df_tg_train = df_devel['target_cls'][df_data_train.index]\n",
    "df_tg_train = df_tg_train.astype(int)\n",
    "df_data_train.drop(columns=['srch_id'], inplace=True)\n",
    "\n",
    "df_data_val = df_devel.loc[df_devel.srch_id.isin(val_ids), predictor_cols]\n",
    "groups_val = get_groups(df_data_val)\n",
    "#df_data_val = df_data_val.dropna() # let's see what happens if we drop all NAs\n",
    "df_val = df_devel.loc[df_data_val.index]\n",
    "df_tg_val = df_devel['target_cls'][df_data_val.index]\n",
    "df_tg_val = df_tg_val.astype(int)\n",
    "df_data_val.drop(columns=['srch_id'], inplace=True)\n",
    "\n",
    "df_test = df_test.set_index('srch_id').sort_index().reset_index()\n",
    "df_data_test = df_test[predictor_cols]\n",
    "groups_test = get_groups(df_data_test)\n",
    "# df_tg_test = df_test['target_cls']\n",
    "# df_tg_test = df_tg_test.astype(int)\n",
    "df_data_test.drop(columns=['srch_id'], inplace=True)\n",
    "\n",
    "df_data_devel = df_devel[predictor_cols]\n",
    "groups_devel = get_groups(df_data_devel)\n",
    "df_tg_devel = df_devel['target_cls']\n",
    "df_tg_devel = df_tg_devel.astype(int)\n",
    "df_data_devel.drop(columns=['srch_id'], inplace=True)\n",
    "\n",
    "#df_data_test = df_data_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409514 583459 11338\n",
      "[]\n",
      "193941 583459 26916\n",
      "[]\n",
      "114620 127783 567\n",
      "['top_prob_prop_id', 'avg_position_prop_id']\n",
      "83083 127783 1330\n",
      "['top_prob_prop_id', 'avg_position_prop_id']\n"
     ]
    }
   ],
   "source": [
    "# def set_prop_agg_to_NA(df, ids):\n",
    "#     cols = [c for c in df.columns if '_prop_id' in c]\n",
    "#     print(cols)\n",
    "#     df.loc[df.prop_id.isin(ids), cols] = pd.NA\n",
    "#\n",
    "# def set_srch_dest_agg_to_NA(df, ids):\n",
    "#     cols = [c for c in df.columns if '_srch_destination_id' in c]\n",
    "#     #cols = 'avg_position_srch_prop_id'\n",
    "#     print(cols)\n",
    "#     df.loc[df.srch_destination_id.isin(ids), cols] = pd.NA\n",
    "#\n",
    "# def set_prop_srch_dest_id_agg_to_NA(df, ids):\n",
    "#     cols = [c for c in df.columns if '_srch_prop_id' in c]\n",
    "#     #cols = 'avg_position_srch_prop_id'\n",
    "#     print(cols)\n",
    "#     df.loc[df.prop_srch_dest_id.isin(ids), cols] = pd.NA\n",
    "\n",
    "def set_avg_position_srch_prop_id_to_NA(df, ids):\n",
    "    cols = [c for c in df.columns if c in ['avg_position_srch_prop_id', 'top_prob_srch_prop_id']]\n",
    "    print(cols)\n",
    "    df.loc[df.prop_srch_dest_id.isin(ids), cols] = pd.NA\n",
    "\n",
    "def set_avg_position_prop_id_to_NA(df, ids):\n",
    "    cols = [c for c in df.columns if c in ['avg_position_prop_id', 'top_prob_prop_id']]\n",
    "    print(cols)\n",
    "    df.loc[df.prop_id.isin(ids), cols] = pd.NA\n",
    "\n",
    "def set_probs_to_NA(df, ids, negate=False):\n",
    "    cols = [c for c in df.columns if '_prob_' in c or 'click' in c]\n",
    "    print(cols)\n",
    "    if len(cols)==0:\n",
    "        return\n",
    "    sel_idx = ~df.prop_srch_dest_id.isin(ids) if negate else df.prop_srch_dest_id.isin(ids)\n",
    "    df.loc[sel_idx, cols] = pd.NA\n",
    "\n",
    "# So first we need to remove the click/book probs for all ids in val only\n",
    "def get_ids_in_one_but_not_the_other(df_in_this, df_not_in_this, col):\n",
    "    in_this = set(df_in_this[col].unique())\n",
    "    not_in_this = set(df_not_in_this[col].unique())\n",
    "    missing = in_this - not_in_this\n",
    "    print(len(in_this), len(not_in_this), len(missing))\n",
    "    return missing\n",
    "\n",
    "# set_prop_srch_dest_id_agg_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_val, df_train, 'prop_srch_dest_id'))\n",
    "# set_prop_srch_dest_id_agg_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_test, df_train, 'prop_srch_dest_id'))\n",
    "#\n",
    "# set_srch_dest_agg_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_val, df_train, 'srch_destination_id'))\n",
    "# set_srch_dest_agg_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_test, df_train, 'srch_destinationf_id'))\n",
    "#\n",
    "# set_prop_agg_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_data_val, df_data_train, 'prop_id'))\n",
    "# set_prop_agg_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_data_test, df_data_train, 'prop_id'))\n",
    "\n",
    "set_avg_position_srch_prop_id_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_data_test, df_data_train, 'prop_srch_dest_id'))\n",
    "set_avg_position_srch_prop_id_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_data_val, df_data_train, 'prop_srch_dest_id'))\n",
    "\n",
    "set_avg_position_prop_id_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_data_test, df_data_train, 'prop_id'))\n",
    "set_avg_position_prop_id_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_data_val, df_data_train, 'prop_id'))\n",
    "\n",
    "# set_probs_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_data_test, df_data_train, 'prop_id'))\n",
    "# set_probs_to_NA(df_data_val, get_ids_in_one_but_not_the_other(df_data_val, df_data_train, 'prop_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_772347/673555134.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data_test.drop(columns=['prop_srch_dest_id', 'srch_destination_id', 'prop_id'], inplace=True)\n",
      "/tmp/ipykernel_772347/673555134.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_data_devel.drop(columns=['prop_srch_dest_id', 'srch_destination_id', 'prop_id'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_data_val.drop(columns=['prop_srch_dest_id', 'srch_destination_id', 'prop_id'], inplace=True)\n",
    "df_data_train.drop(columns=['prop_srch_dest_id', 'srch_destination_id', 'prop_id'], inplace=True)\n",
    "df_data_test.drop(columns=['prop_srch_dest_id', 'srch_destination_id', 'prop_id'], inplace=True)\n",
    "df_data_devel.drop(columns=['prop_srch_dest_id', 'srch_destination_id', 'prop_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prop_review_score missing count 24166 out of 496238 => 5% missing\n",
      "prop_location_score2 missing count 108599 out of 496238 => 22% missing\n",
      "srch_query_affinity_score missing count 464464 out of 496238 => 94% missing\n",
      "hist_starrating_diff missing count 471743 out of 496238 => 95% missing\n",
      "price_hist_logdiff missing count 70493 out of 496238 => 14% missing\n",
      "visitor_hist_adr_usd_logdiff missing count 471669 out of 496238 => 95% missing\n",
      "price_usd_ld_srch_id missing count 9 out of 496238 => 0% missing\n",
      "prop_starrating_w0_d_srch_destination_id missing count 16769 out of 496238 => 3% missing\n",
      "prop_starrating_w0_d_srch_id missing count 16769 out of 496238 => 3% missing\n",
      "prop_review_score_d_srch_destination_id missing count 24166 out of 496238 => 5% missing\n",
      "prop_review_score_d_srch_destination_id__prop_starrating missing count 24166 out of 496238 => 5% missing\n",
      "prop_review_score_d_srch_id missing count 24166 out of 496238 => 5% missing\n",
      "prop_location_score2_d_srch_destination_id missing count 108599 out of 496238 => 22% missing\n",
      "price_usd_ld_srch_id__prop_starrating missing count 9 out of 496238 => 0% missing\n",
      "price_hist_logdiff_d_srch_id missing count 70493 out of 496238 => 14% missing\n",
      "visitor_hist_adr_usd_logdiff_d_srch_id missing count 471669 out of 496238 => 95% missing\n",
      "srch_query_affinity_score_d_srch_id missing count 464464 out of 496238 => 94% missing\n",
      "top_prob_prop_id missing count 1419 out of 496238 => 0% missing\n",
      "avg_position_prop_id missing count 1419 out of 496238 => 0% missing\n"
     ]
    }
   ],
   "source": [
    "for col in df_data_train.columns:\n",
    "    print_missing(df_data_val, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom objective (to be exactly the same as the one used in the competition)\n",
    "\n",
    "# self-defined objective function\n",
    "# f(preds: array, train_data: Dataset) -> grad: array, hess: array\n",
    "# log likelihood loss\n",
    "def custom_ndcg(preds, train_data, *largs, **kwargs):\n",
    "    print('not sure how to do this')\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "       -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def monotone_constraints_from_tuples(tpls):\n",
    "    pass\n",
    "\n",
    "test = [\n",
    "#('promotion_flag', 1),\n",
    "('random_bool', -1),\n",
    "#('comp_better_cnt', -1),\n",
    "#('price_hist_logdiff', -1),\n",
    "#('price_usd_ld_srch_id', -1),\n",
    "#('prop_starrating_w0_d_srch_id', 1),\n",
    "#('prop_location_score1_d_srch_id', 1),\n",
    "#('click_prob_per_prop_id_d_srch_id', 1),\n",
    "]\n",
    "\n",
    "d = {col:i for i, col in enumerate(df_data_train.columns)}\n",
    "\n",
    "mon = np.zeros(len(df_data_train.columns))\n",
    "for t in test:\n",
    "    mon[d[t[0]]]=t[1]\n",
    "\n",
    "mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_column(df):\n",
    "    categorical_features = [\n",
    "        \"day\",\n",
    "        \"month\",\n",
    "        \"prop_country_id\",\n",
    "        \"site_id\",\n",
    "        \"visitor_location_country_id\",\n",
    "        'srch_saturday_night_bool',\n",
    "        'prop_brand_bool',\n",
    "        'same_country',\n",
    "        'random_bool',\n",
    "        'promotion_flag',\n",
    "        #'midstay_week',\n",
    "        'midstay_month',\n",
    "        'midstay_dayofyear',\n",
    "        'midstay_dayofweek',\n",
    "        'booking_week',\n",
    "        'booking_month',\n",
    "        'booking_dayofyear',\n",
    "        'booking_dayofweek' ,\n",
    "#        'prop_starrating',\n",
    "    ]\n",
    "    categorical_features = [c for c in categorical_features if c in df.columns.values]\n",
    "    categorical_features_numbers = [df.columns.get_loc(x) for x in categorical_features]\n",
    "    return categorical_features_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/miniconda3/envs/dmt_expedia/lib/python3.11/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/robert/miniconda3/envs/dmt_expedia/lib/python3.11/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [0, 3, 6, 13, 14, 16, 20]\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_position\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] boosting is set=goss, boosting_type=gbdt will be ignored. Current value: boosting=goss\n",
      "[LightGBM] [Warning] num_threads is set=24, n_jobs=-1 will be ignored. Current value: num_threads=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/miniconda3/envs/dmt_expedia/lib/python3.11/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/robert/miniconda3/envs/dmt_expedia/lib/python3.11/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[20]\ttraining's ndcg@5: 0.38574\tvalid_1's ndcg@5: 0.378665\n",
      "[40]\ttraining's ndcg@5: 0.392909\tvalid_1's ndcg@5: 0.383958\n",
      "[60]\ttraining's ndcg@5: 0.398335\tvalid_1's ndcg@5: 0.38896\n",
      "[80]\ttraining's ndcg@5: 0.402165\tvalid_1's ndcg@5: 0.391674\n",
      "[100]\ttraining's ndcg@5: 0.405071\tvalid_1's ndcg@5: 0.393445\n",
      "[120]\ttraining's ndcg@5: 0.408158\tvalid_1's ndcg@5: 0.394243\n",
      "[140]\ttraining's ndcg@5: 0.410555\tvalid_1's ndcg@5: 0.396091\n",
      "[160]\ttraining's ndcg@5: 0.412653\tvalid_1's ndcg@5: 0.39705\n",
      "[180]\ttraining's ndcg@5: 0.414569\tvalid_1's ndcg@5: 0.397865\n",
      "[200]\ttraining's ndcg@5: 0.41655\tvalid_1's ndcg@5: 0.398616\n",
      "[220]\ttraining's ndcg@5: 0.418534\tvalid_1's ndcg@5: 0.399243\n",
      "[240]\ttraining's ndcg@5: 0.420147\tvalid_1's ndcg@5: 0.399076\n",
      "[260]\ttraining's ndcg@5: 0.421765\tvalid_1's ndcg@5: 0.399733\n",
      "[280]\ttraining's ndcg@5: 0.423553\tvalid_1's ndcg@5: 0.400537\n",
      "[300]\ttraining's ndcg@5: 0.425003\tvalid_1's ndcg@5: 0.400772\n",
      "[320]\ttraining's ndcg@5: 0.426609\tvalid_1's ndcg@5: 0.401311\n",
      "[340]\ttraining's ndcg@5: 0.428142\tvalid_1's ndcg@5: 0.401732\n",
      "[360]\ttraining's ndcg@5: 0.429719\tvalid_1's ndcg@5: 0.40214\n",
      "[380]\ttraining's ndcg@5: 0.430952\tvalid_1's ndcg@5: 0.402262\n",
      "[400]\ttraining's ndcg@5: 0.432646\tvalid_1's ndcg@5: 0.402034\n",
      "[420]\ttraining's ndcg@5: 0.433967\tvalid_1's ndcg@5: 0.40221\n",
      "[440]\ttraining's ndcg@5: 0.435322\tvalid_1's ndcg@5: 0.402154\n",
      "[460]\ttraining's ndcg@5: 0.436731\tvalid_1's ndcg@5: 0.402889\n",
      "[480]\ttraining's ndcg@5: 0.43782\tvalid_1's ndcg@5: 0.402638\n",
      "[500]\ttraining's ndcg@5: 0.439242\tvalid_1's ndcg@5: 0.402388\n",
      "[520]\ttraining's ndcg@5: 0.440691\tvalid_1's ndcg@5: 0.402821\n",
      "[540]\ttraining's ndcg@5: 0.441968\tvalid_1's ndcg@5: 0.402601\n",
      "[560]\ttraining's ndcg@5: 0.443427\tvalid_1's ndcg@5: 0.402646\n",
      "[580]\ttraining's ndcg@5: 0.444661\tvalid_1's ndcg@5: 0.403363\n",
      "[600]\ttraining's ndcg@5: 0.446107\tvalid_1's ndcg@5: 0.404434\n",
      "[620]\ttraining's ndcg@5: 0.447144\tvalid_1's ndcg@5: 0.404265\n",
      "[640]\ttraining's ndcg@5: 0.448498\tvalid_1's ndcg@5: 0.404308\n",
      "[660]\ttraining's ndcg@5: 0.449616\tvalid_1's ndcg@5: 0.404322\n",
      "[680]\ttraining's ndcg@5: 0.450816\tvalid_1's ndcg@5: 0.404188\n",
      "[700]\ttraining's ndcg@5: 0.451862\tvalid_1's ndcg@5: 0.404428\n",
      "[720]\ttraining's ndcg@5: 0.453031\tvalid_1's ndcg@5: 0.404443\n",
      "[740]\ttraining's ndcg@5: 0.454522\tvalid_1's ndcg@5: 0.404398\n",
      "[760]\ttraining's ndcg@5: 0.455795\tvalid_1's ndcg@5: 0.404578\n",
      "[780]\ttraining's ndcg@5: 0.456787\tvalid_1's ndcg@5: 0.404855\n",
      "[800]\ttraining's ndcg@5: 0.457839\tvalid_1's ndcg@5: 0.404941\n",
      "[820]\ttraining's ndcg@5: 0.458971\tvalid_1's ndcg@5: 0.404805\n",
      "[840]\ttraining's ndcg@5: 0.460065\tvalid_1's ndcg@5: 0.405033\n",
      "[860]\ttraining's ndcg@5: 0.46107\tvalid_1's ndcg@5: 0.405028\n",
      "[880]\ttraining's ndcg@5: 0.462188\tvalid_1's ndcg@5: 0.404533\n",
      "[900]\ttraining's ndcg@5: 0.463065\tvalid_1's ndcg@5: 0.404515\n",
      "[920]\ttraining's ndcg@5: 0.463908\tvalid_1's ndcg@5: 0.404754\n",
      "Early stopping, best iteration is:\n",
      "[775]\ttraining's ndcg@5: 0.456557\tvalid_1's ndcg@5: 0.405254\n",
      "Evaluated only: ndcg@5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker(boosting=&#x27;goss&#x27;, deterministic=True, label_gain=[0, 1, 5],\n",
       "           lambda_l2=0.001, lambdarank_truncation_level=8, max_depth=5,\n",
       "           max_position=5, metric=&#x27;ndcg&#x27;, n_estimators=11500, num_threads=24,\n",
       "           objective=&#x27;lambdarank&#x27;, random_state=42, subsample_for_bin=400000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker(boosting=&#x27;goss&#x27;, deterministic=True, label_gain=[0, 1, 5],\n",
       "           lambda_l2=0.001, lambdarank_truncation_level=8, max_depth=5,\n",
       "           max_position=5, metric=&#x27;ndcg&#x27;, n_estimators=11500, num_threads=24,\n",
       "           objective=&#x27;lambdarank&#x27;, random_state=42, subsample_for_bin=400000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRanker(boosting='goss', deterministic=True, label_gain=[0, 1, 5],\n",
       "           lambda_l2=0.001, lambdarank_truncation_level=8, max_depth=5,\n",
       "           max_position=5, metric='ndcg', n_estimators=11500, num_threads=24,\n",
       "           objective='lambdarank', random_state=42, subsample_for_bin=400000)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import early_stopping, log_evaluation, LGBMRanker\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "ranker = LGBMRanker(\n",
    "    #objective=\"rank_xendcg\",\n",
    "    objective='lambdarank',\n",
    "    #lambdarank_truncation_level=16,\n",
    "    metric=\"ndcg\",\n",
    "    subsample_for_bin=200000*2,\n",
    "    n_estimators=11500, # this is the max, early stopping will likely result in fewer\n",
    "    # feature_fraction=0.8,\n",
    "    learning_rate=0.1,\n",
    "    #label_gain=[0, 1, 31],\n",
    "    label_gain=[0, 1, 5],\n",
    "    random_state=42,\n",
    "    boosting='goss',\n",
    "    # top_rate=0.13, # goss\n",
    "    # other_rate=0.10, # goss\n",
    "    # --\n",
    "    # boosting='dart',\n",
    "    #boosting='gbdt',\n",
    "    # bagging_fraction=0.9,\n",
    "    # bagging_freq=5,\n",
    "    # bagging_seed=123,\n",
    "    # --\n",
    "    #monotone_constraints=mon,\n",
    "    #monotone_constraints_method='advanced',\n",
    "    #extra_trees=True,\n",
    "    lambda_l2=1e-3,\n",
    "    #lambda_l1=1e-2,\n",
    "    #min_data_in_leaf=40,\n",
    "    max_depth=5,\n",
    "    max_position=5,\n",
    "    deterministic=True,\n",
    "    num_threads=24,\n",
    "    lambdarank_truncation_level=5+3,\n",
    ")\n",
    "\n",
    "x_val = df_data_val\n",
    "Y_val = df_tg_val\n",
    "g_val = groups_val\n",
    "# x_val = df_data_test\n",
    "# Y_val = df_tg_test\n",
    "# g_val = groups_test\n",
    "\n",
    "x_train = df_data_train\n",
    "Y_train = df_tg_train\n",
    "g_train = groups_train\n",
    "# x_train = df_data_devel\n",
    "# Y_train = df_tg_devel\n",
    "# g_train = groups_devel\n",
    "\n",
    "\n",
    "early_stopping_callback = early_stopping(stopping_rounds=150, first_metric_only=True)\n",
    "log_evaluation_callback = log_evaluation(period=20)\n",
    "\n",
    "ranker.fit(\n",
    "    x_train,\n",
    "    Y_train,\n",
    "    eval_set=[(x_train, Y_train), (x_val, Y_val)],\n",
    "    eval_group=[g_train, g_val],\n",
    "    group=g_train,\n",
    "    eval_at=5,\n",
    "    callbacks=[early_stopping_callback, log_evaluation_callback],\n",
    "    categorical_feature=get_categorical_column(x_train),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site_id': 1944,\n",
       " 'prop_starrating': 261,\n",
       " 'prop_review_score': 341,\n",
       " 'prop_brand_bool': 124,\n",
       " 'prop_location_score1': 995,\n",
       " 'prop_location_score2': 1370,\n",
       " 'promotion_flag': 105,\n",
       " 'srch_length_of_stay': 312,\n",
       " 'srch_booking_window': 563,\n",
       " 'srch_adults_count': 156,\n",
       " 'srch_children_count': 146,\n",
       " 'srch_room_count': 57,\n",
       " 'srch_query_affinity_score': 296,\n",
       " 'random_bool': 356,\n",
       " 'booking_dayofweek': 216,\n",
       " 'midstay_week': 354,\n",
       " 'midstay_dayofweek': 265,\n",
       " 'hist_starrating_diff': 249,\n",
       " 'price_hist_logdiff': 1210,\n",
       " 'visitor_hist_adr_usd_logdiff': 360,\n",
       " 'same_country': 83,\n",
       " 'price_usd_ld_srch_id': 1212,\n",
       " 'prop_starrating_w0_d_srch_destination_id': 348,\n",
       " 'prop_starrating_w0_d_srch_id': 206,\n",
       " 'prop_review_score_d_srch_destination_id': 415,\n",
       " 'prop_review_score_d_srch_destination_id__prop_starrating': 473,\n",
       " 'prop_review_score_d_srch_id': 181,\n",
       " 'prop_location_score1_d_srch_destination_id': 1011,\n",
       " 'prop_location_score2_d_srch_destination_id': 1249,\n",
       " 'price_usd_ld_srch_id__prop_starrating': 1011,\n",
       " 'price_hist_logdiff_d_srch_id': 1273,\n",
       " 'visitor_hist_adr_usd_logdiff_d_srch_id': 282,\n",
       " 'srch_query_affinity_score_d_srch_id': 429,\n",
       " 'top_prob_prop_id': 976,\n",
       " 'avg_position_prop_id': 906,\n",
       " 'log_appearance_count_prop_id': 1233,\n",
       " 'avg_res_len_prop_id': 1063,\n",
       " 'comp_known_cnt': 170,\n",
       " 'comp_better_worse': 238}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{f:i for (f, i) in zip(ranker.feature_name_, ranker.feature_importances_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_df(preds, df):\n",
    "    df_prediction = df[[\"srch_id\", \"prop_id\", 'relevance_score']].assign(predicted = preds)\n",
    "    return df_prediction.sort_values(\"predicted\", ascending=False).sort_values(\"srch_id\", kind='stable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_val = get_prediction_df(ranker.predict(df_data_val), df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:23:53.079664029Z",
     "start_time": "2023-05-24T15:23:52.645970829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4052536054473705"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_val.groupby('srch_id')['relevance_score'].apply(lambda x: ndcg_dmt(x, use_2pow=False)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:23:56.840825104Z",
     "start_time": "2023-05-24T15:23:53.080289626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30209086095081694"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_val.groupby('srch_id')['relevance_score'].apply(lambda x: ndcg_sklearn(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df=pd.read_csv('data/test_revealed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T15:28:13.312856925Z",
     "start_time": "2023-05-24T15:27:46.979187747Z"
    }
   },
   "outputs": [],
   "source": [
    "ref_df['relevance_score'] = ref_df.booking_bool * 4.0 + ref_df.click_bool\n",
    "#ref_df\n",
    "df_pred_test = get_prediction_df(\n",
    "    ranker.predict(df_data_test), \n",
    "    df_test[[\"srch_id\", \"prop_id\"]].set_index(['srch_id', 'prop_id']).join(ref_df.set_index(['srch_id', 'prop_id'])[['relevance_score']], how='left').reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-24T15:26:12.024637579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39860938178185"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_test.groupby('srch_id')['relevance_score'].apply(lambda x: ndcg_dmt(x, use_2pow=False)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pred_test.groupby('srch_id')['relevance_score'].apply(lambda x: ndcg_sklearn(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.47409365112587953 - 2000 and [0, 1, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = ranker.predict(df_data_test)\n",
    "\n",
    "df_prediction = df_test[[\"srch_id\", \"prop_id\"]].assign(predicted = preds_test)\n",
    "df_prediction = df_prediction.sort_values(\"predicted\", ascending=False).sort_values(\"srch_id\", kind='stable')\n",
    "#df_prediction[[\"srch_id\", \"prop_id\"]].to_csv(\"data/pred_robert_LGBMRanker_1150.csv.zip\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ok so, there is a problem with a big gap in the performance on the validation set and test set. I think this is due to several factors:\n",
    "* bagging in combination with aggregating over properties and destination. For the validation set to be meaningful we need to ensure that a similar proportion of destination ids are missing from the validation set as the proportion of missing destination ids from the test set\n",
    "* statistics should only be calculated on the training set (do not include the validation set)\n",
    "* the score is more in line with sklearn.metrics.ndgc score, coincidence?\n",
    "\n",
    "Extra features:\n",
    "* calculate z score or quantile for booking day-of-year relative to property stddev or empirical distribution\n",
    "* add df (number of observations)\n",
    "* determine price-usd type depending on the visitor country id and/or site id\n",
    "** figure out the conditions of when it is total amount of booking (e.g. when there is no correlation between room number and gross booking)\n",
    "** check if outliers are correlated (maybe there is some currency conversion going on for some countries)\n",
    "* add all comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
